# -*- coding: utf-8 -*-
"""Copy of DataScience(C pred).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VRXASAXDAB5dqbgK5MvW39dHu3GSb059

### **Importing necessary libraries and files**
"""

import pandas as pd
import numpy as np
import cv2
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")
from sklearn import metrics
from sklearn.decomposition import PCA

"""### **Mounting google drive**

"""

from google.colab import drive
drive.mount('/content/drive')

"""### **Dataset path**"""

dataset_path = "/content/drive/My Drive/ASL_Dataset/ASL_Dataset/"

"""### **Display an image from the dataset**"""

from IPython.display import Image
Image(filename=dataset_path + "amer_sign2.png", width=600, height=300)

from IPython.display import Image
Image(filename=dataset_path + "amer_sign3.png", width=600, height=300)

"""### **Data Collection**

---


The dataset format is patterned to match closely with the classic MNIST. Each
training and
test case represent a label (0-25) as a one-to-one map for each alphabet letter A-Z.
The training data (27,455 cases) and test data (7172 cases) are approximately half the size
of the standard MNIST but otherwise similar with a header row of label, pixel1, pixel2….
pixel 784 which represent a single 28x28 pixel image with grayscale (not RGB) values
between 0-255


---


"""

trainData = pd.read_csv(dataset_path + "sign_mnist_train.csv")
validData = pd.read_csv(dataset_path + "sign_mnist_test.csv")
No_classes = 26

"""### **Data Preprocessing**
Here we will analyse useful pattern of the dataset
"""

print("Training Data Shape:", trainData.shape)
print("Testing Data Shape:", validData.shape)
trainData.head()

"""### **Data Analysis**

Checking for missing values
"""

trainData.isna().sum().max()
# 0 means no missing values

"""Visualizing missing values"""

plt.figure(figsize=(10,8))

colours = ['#34495E', 'seagreen']  # Defining colors for the heatmap
sns.heatmap(trainData.isnull(), cmap=sns.color_palette(colours))

#This plot shows that the data does not have any “horizontal white line” means there are no missing value values.

"""Focusing on structure, labels, and pixel value distribution."""

#Dataset Information
trainData.info()

#total types of classes the image can belong to. [1-24] corrosponds to [a-y]
labels = trainData.label.unique()
np.sort(labels)

#Dataset Statistics
trainData.describe().T

"""Converting the pandas Dataframe into Numpy Arrays

```
We will now need to seperate our features and labels for both test and training datasets
```


"""

x_train = (trainData.drop(columns=["label"])).to_numpy()
y_train = (trainData["label"]).to_numpy()
x_test = (validData.drop(columns=["label"])).to_numpy()
y_test = (validData["label"]).to_numpy()

x_test.shape

classes = np.unique(y_train)

"""## **Visualization**

1. Bar Plot
"""

# Countplot of label distribution
sns.countplot(x='label', data=trainData)

# Pie chart of label distribution
trainData['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', figsize=(6, 6))
plt.title("Label in Total")
plt.show()

"""**INFERENCE:** One thing to observe is that the data is equally distributed. So, we can use
accuracy as a metric to measure performance though precision and recall is also equally
appropriate to use
"""

#The function prints an image using the data
def Show_Train_Image(row):
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 7))
    fig.figsize = (1, 1)
    img = np.reshape(x_train[row], (28, 28))
    print("Actual Label : ", chr(ord('A') + y_train[row]))

    ax1.set_title("Original Image")
    ax1.axis("off")
    ax1.imshow(img)

    ax2.axis("off")
    ax2.set_title("Gray Image")
    ax2.imshow(img, cmap='gray')

Show_Train_Image(345)

"""# **Principle Component Analysis (PCA)**"""

# So we will now do principal component analysis
pca = PCA().fit(x_train)

# Visualizing the cumulative covariance curve
plt.rcParams['figure.figsize'] = (10, 6)

fig, ax = plt.subplots()
x = np.arange(1, 800, step=1)
y = np.cumsum(pca.explained_variance_ratio_)

plt.plot(x[:200:5], y[:200:5], marker="o", color='seagreen', linestyle='--')
plt.xlabel("Number of Components")
plt.xticks(np.arange(0, 200, step=5), rotation=90)
plt.ylabel("Cumulative Variance (%)")
plt.title("Explained Variance Curve")

# We cut the parameters at 95% variance value
plt.axhline(y=0.95, color='r')
plt.text(105, 0.9, "95% cut-off threshold", color='red')

for i, j in zip(x, y):
    if j > 0.95:
        print("The number of components needed to explain variance: ", i)
        break

"""**INFERENCE:** We are using the technique of principle component analysis. Here we set the upper
limit of 95% to capture the top 113 features that have 95% varience, effectively eliminating 672
features.

### **Data Modelling**
"""

Model_name = []
acc_train = []
acc_test = []
def storeResults(models,a , b):
  Model_name.append(models)
  acc_train.append(a)
  acc_test.append(b)

"""  Logistic Regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

log_clf = Pipeline([('reduce_dims', PCA(n_components=113)),
                        ('model', LogisticRegression(multi_class='multinomial',
random_state = 0))])

log_clf.fit(x_train, y_train)

log_predict = log_clf.predict(x_test)
log_predict_train = log_clf.predict(x_train)

y_test

x_test_accuracy = metrics.accuracy_score(y_test, log_predict)
x_train_accuracy = metrics.accuracy_score(y_train, log_predict_train)
print("Logistic Regression : Accuracy on training Data: {:.3f}".format(x_train_accuracy))
print("Logistic Regression : Accuracy on test Data: {:.3f}".format(x_test_accuracy))

"""The accuracy of training data is 100% and the accuracy on test data is 66.7%. Hence it can be
concluded that the model is overfitting

"""

print(metrics.classification_report(y_test, log_predict))

plt.figure(figsize=(6,6))
cm=metrics.confusion_matrix(y_test, log_predict)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Greens')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False);

storeResults("LogisticRegression", x_train_accuracy, x_test_accuracy)

"""### **DecisionTree Classifier**"""

from sklearn.tree import DecisionTreeClassifier
tree_clf = Pipeline([
('reduce-dims', PCA(n_components=113)),
# maximum depth of the tree is 30
('model', DecisionTreeClassifier(max_depth=30))
])
tree_clf.fit(x_train, y_train)

y_train_tree = tree_clf.predict(x_train)
y_test_tree = tree_clf.predict(x_test)

tree_train_accuracy = metrics.accuracy_score(y_train, y_train_tree)
tree_test_accuracy = metrics.accuracy_score(y_test, y_test_tree)
print("Decision Tree : Accuracy on training Data: {:.3f}".format(tree_train_accuracy))
print("Decision Tree : Accuracy on test Data: {:.3f}".format(tree_test_accuracy))

print(metrics.classification_report(y_test, y_test_tree))

"""accuracy for decision tree classifier is 0.41, precision is 0.42 and recall is 0.41. Since all the
parameters are low but accuracy on training data is 1.00 we can say that the model is overfitting.
"""

plt.figure(figsize=(10,10))
cm=metrics.confusion_matrix(y_test,y_test_tree)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Greens')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False);

"""This code snippet is analyzing how the performance of a Decision Tree model changes with different tree depths."""

training_accuracy = []
test_accuracy = []

# try max_depth from 1 to 30
depth = range(1, 31)
for n in depth:
    tree_test = Pipeline([('reduce_dims', PCA(n_components=113)),
                          ('model', DecisionTreeClassifier(max_depth=n))])

    tree_test.fit(x_train, y_train)
    # record training set accuracy
    training_accuracy.append(tree_test.score(x_train, y_train))
    # record generalization accuracy
    test_accuracy.append(tree_test.score(x_test, y_test))

# plotting the training & testing accuracy for max_depth from 1 to 30
plt.plot(depth, training_accuracy, label="training accuracy", color="green")
plt.plot(depth, test_accuracy, label="test accuracy", color="orange")
plt.ylabel("Accuracy")
plt.xlabel("max_depth")
plt.legend()

"""It visually shows how the tree's complexity affects performance:
*   Low depth (underfitting): both accuracies are low.
*   Medium depth (optimal): test accuracy peaks.
*   High depth (overfitting): training accuracy stays high, but test accuracy
  drops.

**Inferences:** We can see that test accuracy is saturated after max-depth of 15 and same goes for
train accuracy. The accuracy on test is set is very low hence this is not a good model for the dataset.
"""

storeResults("Decision Tree", tree_train_accuracy, tree_test_accuracy)

"""### **Support Vector Machines**"""

#Support Vector Classifier model
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
# instantiate the model
svc= Pipeline([('reduce_dims', PCA(n_components=113)),('model', SVC())])
# fit the model
svc.fit(x_train,y_train)

y_train_svc = svc.predict(x_train)
y_test_svc = svc.predict(x_test)

acc_train_svc = metrics.accuracy_score(y_train,y_train_svc)
acc_test_svc = metrics.accuracy_score(y_test,y_test_svc)
print("Support Vector Machine : Accuracy on training Data: {:.3f}".format(acc_train_svc))
print("Support Vector Machine : Accuracy on test Data: {:.3f}".format(acc_test_svc))

print(metrics.classification_report(y_test, y_test_svc))

"""While 100% training accuracy can be a sign of overfitting, in this case, the test accuracy is still quite high (85.2%) — which means the model generalizes well to unseen data. Therefore we cannot comment on overfitting."""

plt.figure(figsize=(10,10))
cm=metrics.confusion_matrix(y_test,y_test_svc)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Greens')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False);

storeResults("Decision Tree", acc_train_svc, acc_test_svc)



"""The accuracy on the test data set is 85.2% which is good for a statistical machine learning algorithm.

### **Random Forest Classifier**
"""

#Random Forest Classifier Model
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
# instantiate the model
forest = Pipeline([('reduce_dims', PCA(n_components=113)),
('model', RandomForestClassifier(n_estimators=100))])
# fit the model
forest.fit(x_train,y_train)

y_train_forest = forest.predict(x_train)
y_test_forest = forest.predict(x_test)

acc_train_forest = metrics.accuracy_score(y_train,y_train_forest)
acc_test_forest = metrics.accuracy_score(y_test,y_test_forest)
print("Random Forest : Accuracy on training Data: {:.3f}".format(acc_train_forest))
print("Random Forest : Accuracy on test Data: {:.3f}".format(acc_test_forest))

"""Random Forest is showing signs of overfitting — training accuracy is too perfect, and test accuracy drops significantly."""

print(metrics.classification_report(y_test, y_test_forest))

plt.figure(figsize=(10,10))
cm=metrics.confusion_matrix(y_test,y_test_forest)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Greens')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False);

storeResults("Random Forest Classifier", acc_train_forest, acc_test_forest)

"""### **Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB
from sklearn.pipeline import Pipeline
# instantiate the model
nb= Pipeline([('reduce_dims', PCA(n_components=113)),('model', GaussianNB())])
# fit the model
nb.fit(x_train,y_train)

y_train_nb = nb.predict(x_train)
y_test_nb = nb.predict(x_test)

acc_train_nb = metrics.accuracy_score(y_train,y_train_nb)
acc_test_nb = metrics.accuracy_score(y_test,y_test_nb)
print("Naive Bayes : Accuracy on training Data: {:.3f}".format(acc_train_nb))
print("Naive Bayes : Accuracy on test Data: {:.3f}".format(acc_test_nb))

print(metrics.classification_report(y_test, y_test_nb))

plt.figure(figsize=(10,10))
cm=metrics.confusion_matrix(y_test,y_test_nb)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Greens')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False);

storeResults("Naive Bayes", acc_train_nb, acc_test_nb)

"""K-Nearest Classifier model"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline
# instantiate the model
knn = Pipeline([('reduce_dims', PCA(n_components=113)),('model',KNeighborsClassifier())])
# fit the model
knn.fit(x_train,y_train)

y_train_knn = knn.predict(x_train)
y_test_knn = knn.predict(x_test)

acc_train_knn = metrics.accuracy_score(y_train,y_train_knn)
acc_test_knn = metrics.accuracy_score(y_test,y_test_knn)
print("K neighest neighbour : Accuracy on training Data: {:.3f}".format(acc_train_knn))
print("K neighest neighbour : Accuracy on test Data: {:.3f}".format(acc_test_knn))

print(metrics.classification_report(y_test, y_test_knn))

plt.figure(figsize=(10,10))
cm=metrics.confusion_matrix(y_test,y_test_knn)
cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
fig, ax = plt.subplots(figsize=(15,15))
sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Greens')
plt.title("Confusion Matrix")
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show(block=False);

training_accuracy = []
test_accuracy = []

# Try max_depth from 1 to 50, stepping by 5
depth = range(1, 52, 5)

for n in depth:
    knn = Pipeline([
        ('reduce_dims', PCA(n_components=113)),
        ('model', KNeighborsClassifier(n_neighbors=n))
    ])
    knn.fit(x_train, y_train)

    # Record training set accuracy
    training_accuracy.append(knn.score(x_train, y_train))
    # Record generalization accuracy
    test_accuracy.append(knn.score(x_test, y_test))

# Plotting the training & testing accuracy
plt.plot(depth, training_accuracy, label="training accuracy", color='green')
plt.plot(depth, test_accuracy, label="test accuracy", color='orange')
plt.ylabel("Accuracy")
plt.xlabel("n_neighbors")
plt.legend()
plt.show()

storeResults("KNN Classifier", acc_train_knn, acc_test_knn)

"""### **Deep Learning using CNN**"""

x_train = x_train.reshape(len(x_train),28,28,1)
x_train = x_train/255.0
x_test = x_test.reshape(len(x_test),28,28,1)
x_test = x_test/255.0

x_train.shape, y_train.shape, x_test.shape, y_test.shape

model = tf.keras.models.Sequential()
model.add(tf.keras.layers.Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Conv2D(15, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))
model.add(tf.keras.layers.Dropout(0.2))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(128, activation='relu'))
model.add(tf.keras.layers.Dense(50, activation='relu'))
model.add(tf.keras.layers.Dense(26, activation='softmax'))

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(x_train, y_train, epochs=7, validation_data=(x_test, y_test))
model.save("sign_language_mnist_cnn.h5")

testImage = x_test[:24]  # We will take 24 images from the testing dataset

# prediction = model.predict(testImage.reshape(-1, 28, 28, 1))  # Model takes input as 4-dimensional

prediction = model.predict(testImage.reshape(24, 28, 28, 1))
prediction.shape

cnn_train_acc = model.evaluate(x_train, y_train)[1]
cnn_test_acc = model.evaluate(x_test, y_test)[1]
storeResults("Convolutional Neural Network", cnn_train_acc, cnn_test_acc)

result = pd.DataFrame({
    "ML Model": Model_name,
    "Train Accuracy": acc_train,
    "Test Accuracy": acc_test,
})

result

"""Video"""

!pip install opencv-python-headless

from IPython.display import display, Javascript

display(Javascript('''
(async () => {
  const div = document.createElement('div');
  const video = document.createElement('video');
  video.style.border = '2px solid #ccc';
  video.style.borderRadius = '10px';
  video.style.marginTop = '10px';
  video.autoplay = true;
  video.width = 320;
  video.height = 240;

  const stream = await navigator.mediaDevices.getUserMedia({ video: true });
  video.srcObject = stream;
  div.appendChild(video);
  document.body.appendChild(div);
})();
'''))

from google.colab.output import eval_js
from base64 import b64decode
from IPython.display import Javascript
import io

video_path = '/content/video.mp4'

def record_video():
    js_code = """
    async function recordVideo() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true });
      const recorder = new MediaRecorder(stream);
      const data = [];

      recorder.ondataavailable = event => data.push(event.data);
      recorder.start();

      // Create a stop button
      const stopButton = document.createElement('button');
      stopButton.textContent = 'Stop Recording';
      stopButton.style.marginTop = '10px';
      document.body.appendChild(stopButton);

      // Wait for the stop button to be clicked
      await new Promise(resolve => stopButton.onclick = resolve);

      recorder.stop();
      await new Promise(resolve => recorder.onstop = resolve);
      stream.getTracks().forEach(track => track.stop());
      stopButton.remove();

      const blob = new Blob(data, { type: 'video/mp4' });
      const reader = new FileReader();
      reader.onload = () => {
        google.colab.kernel.invokeFunction('notebook.saveVideo', [reader.result], {});
      };
      reader.readAsDataURL(blob);
    }
    recordVideo();
    """
    display(Javascript(js_code))

def save_video(data_url):
    header, encoded = data_url.split(",", 1)
    decoded = b64decode(encoded)
    with open(video_path, "wb") as f:
        f.write(decoded)

from google.colab import output
output.register_callback('notebook.saveVideo', save_video)

print("Click 'Stop Recording' to end the video capture.")
record_video()

import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow  # Add this at the top

# Load your trained model
model = load_model("sign_language_mnist_cnn.h5")

# Read saved video
cap = cv2.VideoCapture("/content/video.mp4")
frame_buffer = []
diff_scores = []

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # Define ROI
    x1, y1, x2, y2 = 50, 50, 250, 250
    roi = frame[y1:y2, x1:x2]

    # Show the ROI while processing (for debugging)
    cv2_imshow(roi)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

    # Preprocess ROI
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
    resized = cv2.resize(gray, (28, 28))
    _, thresh = cv2.threshold(resized, 100, 255, cv2.THRESH_BINARY)
    norm_frame = resized.astype('float32') / 255.0


    frame_buffer.append(norm_frame)

    if len(frame_buffer) > 1:
        diff = np.mean(np.abs(frame_buffer[-1] - frame_buffer[-2]))
        diff_scores.append(diff)

cap.release()
cv2.destroyAllWindows()

# Choose the most stable frame
if len(frame_buffer) == 0:
    print("❌ No frames found!")
    best_frame = None
elif len(diff_scores) == 0:
    print("⚠️ Not enough variation. Using last frame.")
    best_frame = frame_buffer[-1]
else:
    stable_index = np.argmin(diff_scores) + 1
    best_frame = frame_buffer[stable_index]

if best_frame is not None:
    input_frame = best_frame.reshape(1, 28, 28, 1)  # Ensure correct input shape

    # Save image to verify if needed
    from PIL import Image
    img = Image.fromarray((best_frame * 255).astype(np.uint8))
    img.save("/content/input_used_for_prediction.png")

    # Predict
    prediction = model.predict(input_frame)
    predicted_class = np.argmax(prediction)

    # Class map
    labels_map = [chr(i) for i in range(65, 91) if chr(i) not in ['J', 'Z']]
    predicted_letter = labels_map[predicted_class]

    print(f"✅ Predicted Sign: {predicted_letter}")
    print("Prediction probabilities:", prediction)
    print(f"Prediction confidence: {np.max(prediction):.2f}")

    # Show the image used for prediction
    plt.imshow(best_frame, cmap='gray')
    plt.title(f"Predicted: {predicted_letter}")
    plt.axis('off')
    plt.show()

    plt.imshow(best_frame.squeeze(), cmap='gray')
    plt.title("Best frame sent to model")
    plt.axis('off')
    plt.show()
else:
    print("❌ No stable frame selected.")